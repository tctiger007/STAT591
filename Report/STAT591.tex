\documentclass[11pt]{report}
\usepackage{./assignment}
\usepackage{slashbox}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage{stmaryrd}
\usepackage[final]{pdfpages}
\usepackage{array}
\usepackage{multirow}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{epstopdf}

\input{./Definitions}

\begin{document}
\title{
  \huge STAT 591 Summary Report \\ 
  \vspace{10mm}
  \large  Functional Data Analysis for Sparse Longitudinal Data\\
  \normalsize Fang Yao, Hans-Georg M\"{u}ller \& Jane-Ling Wang}

\author{Wangfei Wang \\ wwang75@uic.edu }

\graphicspath{./Figures/}

\maketitle

\section{SUMMARY OF CONTRIBUTIONS}
Functional principal components (FPC) analysis can reduce random trajectories of random curves to a set of FPC scores, and therefore is popular in longitudinal data analysis. 
For a given sample of random trajectories, FPC analysis characterizes the dominant mode of variation  around an overall mean trend function. 

In longitudinal data analysis, there are extensive research of FPC analysis on repeated measures at a dense grid of regularly spaced time points. 
However, it is not uncommon that repeated measurements are infrequent, and these measurements are irregularly spaced per subject. 
In this situation, FPC analysis has limitations because of the sparse repeated measurements. 
The authors summarized a few available models that can be applied to irregular grid of time measurements. 
For example, kernel-based functional principal components analysis for repeated measurements with irregular time points was proposed by Staniswalis and Lee [refs]. %%%%%\cite{}. 
Their method was further studied by other groups [refs]; %%%%%\\cite{}; 
however, when the measurement time points vary widely across individuals and the measurements per subject is very sparse (i.e., one or two measurements per subject), the FPC scores cannot be approximated by the usual integration method. 
Some other groups proposed that by using linear mixed models or reduced-rank mixed effects models, they could use B-splines to model the individual curves with random coefficients [refs]. %%%%%\cite{}.
But because of the complexity of the models, the asymptotic properties of the estimated components were not investigated. 

Taken together, the authors proposed a simpler and more straightforward method to determine eigenfunctions, which they represent the trajectories directly using the Karhunen-Lo\`{e}ve expansion.
Their contributions include:
\begin{itemize}
	\item They proposed a version of functional principal components (FPC) analysis, in which they framed the FPC scores as conditional expectations.
	And thus they coined this method ``principal components analysis through conditional expectation (PACE)''.
	\item In the model, they took into account the additional measurement errors. 
	\item They derived the asymptotic consistency properties.
	\item They derived the asymptotic distribution needed for obtaining point-wise confidence intervals for individual trajectories. 
\end{itemize}

\section{INNOVATION} 
\begin{itemize}
	\item The proposed conditional model is designed for sparse and irregular longitudinal data. 
	\item Under Gaussian assumptions, the authors showed that estimation of individual FPC scores are the best prediction; and under non-Gaussian assumption, they provide estimates for best linear prediction. 
	\item One-curve-leave-out cross-validation was proposed to choose auxiliary parameters. 
	\item Akaike information criterion (AIC) was used for faster computation to select eigenfunctions. 
\end{itemize}

\section{FUNCTIONAL PRINCIPAL COMPONENTS ANALYSIS FOR SPARSE DATA}

\subsection*{Model with Measurement Errors}
The authors modeled the sparse functional data as noisy sampled points from trajectories. 
These trajectories are assumed independent realizations of a smooth random function with unknown mean $\expec{X(t)} = \mu(t)$ and covariance function $cov(X(s), X(t)) = G(s,t)$, where domain of X($\cdot$) is $\mathcal{T}$.
It was assumed that G has an orthogonal expansion in terms of eigenfunction $\phi_k$ and eigenvalues $\lambda_k$: $G(s,t) = \sum_k{\lambda_k\phi_k(s)\phi_k(t)}, \; \; t, s \in \mathcal{T}$, where $\lambda_1 \geq \lambda_2 \geq \cdot \cdot \cdot$.


\begin{align}
	\label{eq:eq1}
	Y_{ij} &= X_i(T_{ij}) + \epsilon_{ij}  \\
	&= \mu(T_{ij}) + \sum_{k=1}^\infty \xi_{ik}\phi_k(T_{ij}) + \epsilon_{ij}, \; \; \;  T_{ij} \in \mathcal{T} 
\end{align}
where $\expec{\epsilon_{ij}} = 0$, var($\epsilon_{ij}$) = $\sigma^2$


\subsection*{Estimation of the Model Components}
In equation \eqref{eq:eq1}, $cov(Y_{ij}, Y_{il} = cov(X(T_{ij}, X(T))))$

\subsection*{Functional Principal Components Analysis Through Conditional Expectation}

\subsection*{Asymptotic Confidence Bands for Individual Trajectories}

\section{ASYMPTOTIC PROPERTIES}

\section{SIMULATION STUDIES}

\section{APPLICATIONS}

\subsection*{Longitudinal CD4 Counts}

\subsection*{Yeast Cell Cycle Gene Expression Profiles}





\end{document}
