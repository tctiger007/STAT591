\documentclass[11pt]{report}
\usepackage{./assignment2}
\usepackage{slashbox}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage{stmaryrd}
\usepackage[final]{pdfpages}
\usepackage{array}
\usepackage{multirow}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{indentfirst}
\usepackage{bbm}
\usepackage{wrapfig}

%\usepackage{biblatex}





\input{./Definitions}
\setlength{\parindent}{3em}
\setlength{\parskip}{0em}


\begin{filecontents*}{ref.bib}
@article{Muller2008,
abstract = {In commonly used functional regression models, the regression of a scalar or functional response on the functional predictor is assumed to be linear. This means that the response is a linear function of the functional principal component scores of the predictor process. We relax the linearity assumption and propose to replace it by an additive structure, leading to a more widely applicable and much more flexible framework for functional regression models. The proposed functional additive regression models are suitable for both scalar and functional responses. The regularization needed for effective estimation of the regression parameter function is implemented through a projection on the eigenbasis of the covariance operator of the functional components in the model. The use of functional principal components in an additive rather than linear way leads to substantial broadening of the scope of functional regression models and emerges as a natural approach, because the uncorrelatedness of the functional principal components is shown to lead to a straightforward implementation of the functional additive model, based solely on a sequence of one-dimensional smoothing steps and without the need for backfitting. This facilitates the theoretical analysis, and we establish the asymptotic consistency of the estimates of the components of the functional additive model. We illustrate the empirical performance of the proposed modeling framework and estimation methods through simulation studies and in applications to gene expression time course data. {\textcopyright} 2008 American Statistical Association.},
author = {M{\"{u}}ller, Hans Georg and Yao, Fang},
doi = {10.1198/016214508000000751},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/Functional Additive Models.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Additive model,Asymptotics,Functional data analysis,Functional regression,Linear model,Principal components,Smoothing,Stochastic processes},
number = {484},
pages = {1534--1544},
title = {{Functional additive models}},
volume = {103},
year = {2008}
}
@article{Rice2001,
author = {Rice, John A and Wu, Colin O.},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/j.0006-341X.2001.00253.x.pdf:pdf},
journal = {Biometrics},
keywords = {metrics},
number = {March},
pages = {253--259},
title = {{Unequally Sampled Noisy Curves}},
volume = {57},
year = {2001}
}
@article{Besse1997,
author = {Besse, Philippe C. and Herve, Cardot and Frederic, Ferraty},
journal = {Computational Statistics {\&} Data Analysis},
number = {3},
pages = {255--270},
title = {{Simultaneous nonparametric regression of unbalanced longitudinal data}},
volume = {24},
year = {1997}
}
@article{Kaslow1987,
author = {Kaslow, Richard A and Ostrow, David G. and Detels, Roger and Phair, John P. and Polk, B Frank and {Charles R. Rinaldo}, Jr.},
journal = {Journal of Epidemiology},
number = {2},
pages = {310--318},
title = {{The multicenter AIDS cohort study: rationale, organization, and selected characteristics of the participants}},
volume = {126},
year = {1987}
}
@article{Spellman1998,
abstract = {We sought to create a comprehensive catalog of yeast genes whose transcript levels vary periodically within the cell cycle. To this end, we used DNA microarrays and samples from yeast cultures synchronized by three independent methods: $\alpha$ factor arrest, elutriation, and arrest of a cdc15 temperature-sensitive mutant. Using periodicity and correlation algorithms, we identified 800 genes that meet an objective minimum criterion for cell cycle regulation. In separate experiments, designed to examine the effects of inducing either the G1 cyclin Cln3p or the B-type cyclin Clb2p, we found that the mRNA levels of more than half of these 800 genes respond to one or both of these cyclins. Furthermore, we analyzed our set of cell cycle-regulated genes for known and new promoter elements and show that several known elements (or variations thereof) contain information predictive of cell cycle regulation. A full description and complete data sets are available at http://cellcycle-www.stanford.edu.},
author = {Spellman, Paul T. and Sherlock, Gavin and Zhang, Michael Q. and Iyer, Vishwanath R. and Anders, Kirk and Eisen, Michael B. and Brown, Patrick O. and Botstein, David and Futcher, Bruce},
doi = {10.1091/mbc.9.12.3273},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/mbc.9.12.3273.pdf:pdf},
issn = {10591524},
journal = {Molecular Biology of the Cell},
number = {12},
pages = {3273--3297},
pmid = {9843569},
title = {{Comprehensive identification of cell cycle-regulated genes of the yeast Saccharomyces cerevisiae by microarray hybridization}},
volume = {9},
year = {1998}
}
@article{Staniswalis1998,
abstract = {Nonparametric methods are developed for estimating the dose effect when a response consists of correlated observations over time measured in a dose–response experiment. The methods can also be applied to data collected from a completely randomized design experiment. Methods are developed for the detection and description of the effects of dose, time, and their interaction. The methods allow for individual variation in the timing and number of observations. A generalization allowing baseline covariates to be incorporated is addressed. These results may be used in an exploratory fashion in the process of building a random-effects model for longitudinal data. {\textcopyright} 1998 Taylor {\&} Francis Group, LLC.},
author = {Staniswalis, Joan G. and Lee, J. Jack},
doi = {10.1080/01621459.1998.10473801},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/2670055.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Growth curves,Kernel estimator,Principal component analysis,Repeated measures},
number = {444},
pages = {1403--1418},
title = {{Nonparametric regression analysis of longitudinal data}},
volume = {93},
year = {1998}
}
@article{James2003,
abstract = {We develop a flexible model-based procedure for clustering functional data. The technique can be applied to all types of curve data but is particularly useful when individuals are observed at a sparse set of time points. In addition to producing final cluster assignments, the procedure generates predictions and confidence intervals for missing portions of curves. Our approach also provides many useful tools for evaluating the resulting models. Clustering can be assessed visually via low-dimensional representations of the curves, and the regions of greatest separation between clusters can be determined using a discriminant function. Finally, we extend the model to handle multiple functional and finite-dimensional covariates and show how it can be applied to standard finite-dimensional clustering problems involving missing data.},
author = {James, Gareth M. and Sugar, Catherine A.},
doi = {10.1198/016214503000189},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/Clustering for Sparsely Sampled Functional Data.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Curve estimation,Discriminant functions,Functional clustering,High-dimensional data},
number = {462},
pages = {397--408},
title = {{Clustering for sparsely sampled functional data}},
volume = {98},
year = {2003}
}
@article{Yao2005,
abstract = {We propose a nonparametric method to perform functional principal components analysis for the case of sparse longitudinal data. The method aims at irregularly spaced longitudinal data, where the number of repeated measurements available per subject is small. In contrast, classical functional data analysis requires a large number of regularly spaced measurements per subject We assume that the repeated measurements are located randomly with a random number of repetitions for each subject and are determined by an underlying smooth random (subject-specific) trajectory plus measurement errors. Basic elements of our approach are the parsimonious estimation of the co-variance structure and mean function of the trajectories, and the estimation of the variance of the measurement errors. The eigenfunction basis is estimated from the data, and functional principal components score estimates are obtained by a conditioning step. This conditional estimation method is conceptually simple and straightforward to implement A key step is the derivation of asymptotic consistency and distribution results under mild conditions, using tools from functional analysis. Functional data analysis for sparse longitudinal data enables prediction of individual smooth trajectories even if only one or few measurements are available for a subject. Asymptotic pointwise and simultaneous confidence bands are obtained for predicted individual trajectories, based on asymptotic distributions, for simultaneous bands under the assumption of a finite number of components. Model selection techniques, such as the Akaike information criterion, are used to choose the model dimension corresponding to the number of eigenfunctions in the model. The methods are illustrated with a simulation study, longitudinal CD4 data for a sample of AIDS patients, and time-course gene expression data for the yeast cell cycle. {\textcopyright} 2005 American Statistical Association.},
author = {Yao, Fang and M{\"{u}}ller, Hans Georg and Wang, Jane Ling},
doi = {10.1198/016214504000001745},
file = {:Users/wangfei/Documents/Courses/STAT/STAT591{\_}Wang/Final{\_}Project/Functional Data Analysis for Sparse Longitudinal Data.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Asymptotics,Conditioning,Confidence band,Measurement error,Principal components,Simultaneous inference,Smoothing},
number = {470},
pages = {577--590},
title = {{Functional data analysis for sparse longitudinal data}},
volume = {100},
year = {2005}
}
@article{Yao2005a,
abstract = {We propose nonparametric methods for functional linear regression which are designed for sparse longitudinal data, where both the predictor and response are functions of a covariate such as time. Predictor and response processes have smooth random trajectories, and the data consist of a small number of noisy repeated measurements made at irregular times for a sample of subjects. In longitudinal studies, the number of repeated measurements per subject is often small and may be modeled as a discrete random number and, accordingly, only a finite and asymptotically nonincreasing number of measurements are available for each subject or experimental unit. We propose a functional regression approach for this situation, using functional principal component analysis, where we estimate the functional principal component scores through conditional expectations. This allows the prediction of an unobserved response trajectory from sparse measurements of a predictor trajectory. The resulting technique is flexible and allows for different patterns regarding the timing of the measurements obtained for predictor and response trajectories. Asymptotic properties for a sample of n subjects are investigated under mild conditions, as n → ∞, and we obtain consistent estimation for the regression function. Besides convergence results for the components of functional linear regression, such as the regression parameter function, we construct asymptotic pointwise confidence bands for the predicted trajectories. A functional coefficient of determination as a measure of the variance explained by the functional regression model is introduced, extending the standard R2 to the functional case. The proposed methods are illustrated with a simulation study, longitudinal primary biliary liver cirrhosis data and an analysis of the longitudinal relationship between blood pressure and body mass index. {\textcopyright} Institute of Mathematical Statistics, 2005.},
author = {Yao, Fang and Muller, Hans Georg and Wang, Jane Ling},
doi = {10.1214/009053605000000660},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/euclid.aos.1140191677.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Asymptotics,Coefficient of determination,Confidence band,Eigenfunctions,Functional data analysis,Prediction,Repeated measurements,Smoothing,Stochastic process},
number = {6},
pages = {2873--2903},
title = {{Functional linear regression analysis for longitudinal data}},
volume = {33},
year = {2005}
}
@article{Boularan1994,
abstract = {We develop in this paper a two-stage nonparametric method for estimating growth curves. Our two-stage additive model consists in assuming that dependence between height and age is a sum of two components, the former being the same for all the individuals. We estimate both functional components by nonparametric kernel smoothing techniques. We first give theoretical results concerning L1,L2 and L∞ rates of convergence for our estimates. Then we discuss how to choose the smoothing degree in an optimal way. This method is then applied to a real example. {\textcopyright} 1994.},
author = {Boularan, Jo{\"{e}}l and Ferr{\'{e}}, Louis and Vieu, Philippe},
doi = {10.1016/0378-3758(94)90014-0},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/1-s2.0-0378375894900140-main.pdf:pdf;:Users/wangfei/Library/Application Support/Mendeley Desktop/Downloaded/Boularan, Ferr{\'{e}}, Vieu - 1994 - Growth curves a two-stage nonparametric approach.pdf:pdf},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Additive model,growth curves,kernel smoothing,nonparametric mixed effects model,two-stage procedure},
number = {3},
pages = {327--350},
title = {{Growth curves: a two-stage nonparametric approach}},
volume = {38},
year = {1994}
}
@article{Journal2019,
author = {Shi, Minggao and Weiss, Robert E. and Taylor, Jeremy M. G.},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/2986151.pdf:pdf},
journal = {Applied Statistics},
number = {2},
pages = {151--163},
title = {{An analysis of paediatric CD4 Counts for acquired immune deficiency syndrome using flexible random curves}},
volume = {45},
year = {1996}
}
@article{Hastie2017,
author = {James, Gareth M. and Hastie, Trevor J. and Sugar, Catherine A.},
file = {:Users/wangfei/Documents/GitHub/STAT591/References/2673632.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {587--602},
title = {{Principal component models for sparse functional data}},
volume = {87},
year = {2000}
}

\end{filecontents*}


\begin{document}

\title{
  \huge STAT 591 Summary Report \\ 
  \vspace{10mm}
  \large  Functional Data Analysis for Sparse Longitudinal Data\\
  \normalsize Fang Yao, Hans-Georg M\"{u}ller \& Jane-Ling Wang}

\author{Wangfei Wang \\ wwang75@uic.edu }

\graphicspath{{./Figures/}}

\maketitle

%\clearpage


\section{SUMMARY OF CONTRIBUTIONS}
Functional principal components (FPC) analysis can reduce random trajectories of random curves to a set of FPC scores, and therefore is popular in longitudinal data analysis. 
For a given sample of random trajectories, FPC analysis characterizes the dominant mode of variation  around an overall mean trend function. 

In longitudinal data analysis, there are extensive research of FPC analysis on repeated measures at a dense grid of regularly spaced time points. 
However, it is not uncommon that repeated measurements are infrequent, and these measurements are irregularly spaced per subject. 
In this situation, FPC analysis has limitations because of the sparse repeated measurements. 
The authors summarized a few available models that can be applied to irregular grid of time measurements. 
For example, kernel-based functional principal components analysis for repeated measurements with irregular time points was proposed by Staniswalis and Lee \cite{Staniswalis1998}. 
Their method was further studied by other groups \cite{Besse1997, Boularan1994}; 
however, when the measurement time points vary widely across individuals and the measurements per subject is very sparse (i.e., one or two measurements per subject), the FPC scores cannot be approximated by the usual integration method. 
Some other groups proposed that by using linear mixed models or reduced-rank mixed effects models, they could use B-splines to model the individual curves with random coefficients \cite{Journal2019, Rice2001, Hastie2017, James2003}.
But because of the complexity of the models, the asymptotic properties of the estimated components were not investigated. 

Taken together, the authors proposed a simpler and more straightforward method to determine eigenfunctions, which they represent the trajectories directly using the Karhunen-Lo\`{e}ve expansion.
Their contributions include: 1) They proposed a version of functional principal components (FPC) analysis, in which they framed the FPC scores as conditional expectations. 
	And thus they coined this method ``principal components analysis through conditional expectation (PACE)''.
	2) In the model, they took into account the additional measurement errors. 
	3) They derived the asymptotic consistency properties.
	4) They derived the asymptotic distribution needed for obtaining point-wise confidence intervals for individual trajectories. 

\section{INNOVATION} 
	1) The proposed conditional model is designed for sparse and irregular longitudinal data. 
	2) Under Gaussian assumptions, the authors showed that estimation of individual FPC scores are the best prediction; and under non-Gaussian assumption, they provide estimates for best linear prediction. 
	3) One-curve-leave-out cross-validation was proposed to choose auxiliary parameters. 
	4) Akaike information criterion (AIC) was used for faster computation to select eigenfunctions. 

\section{FUNCTIONAL PRINCIPAL COMPONENTS ANALYSIS FOR SPARSE DATA}

\subsection*{Model with Measurement Errors}
The authors modeled the sparse functional data as noisy sampled points from trajectories. 
These trajectories are assumed independent realizations of a smooth random function with unknown mean $E{X(t)} = \mu(t)$ and covariance function $cov(X(s), X(t)) = G(s,t)$, where domain of X($\cdot$) is $\mathcal{T}$.
It was assumed that G has an orthogonal expansion in terms of eigenfunction $\phi_k$ and eigenvalues $\lambda_k$: $G(s,t) = \sum_k{\lambda_k\phi_k(s)\phi_k(t)}, \; \; t, s \in \mathcal{T}$, where $\lambda_1 \geq \lambda_2 \geq \cdot \cdot \cdot$.
Assuming $Y_{ij}$ is the jth observation of the random function X($\cdot$) made at a random time $T_{ij}$ and let $\epsilon_{ij}$ be the measurement errors that are iid and are independent of random coefficients $\xi_{ik}$, where $i = 1, ..., n; j = 1, ..., N_i; k = 1, 2, ...$, the authors constructed a model: 
\begin{align}
	\label{eq:eq1}
	Y_{ij} = X_i(T_{ij}) + \epsilon_{ij}  
	= \mu(T_{ij}) + \sum_{k=1}^\infty \xi_{ik}\phi_k(T_{ij}) + \epsilon_{ij}, \; \; \;  T_{ij} \in \mathcal{T} 
\end{align}
where $E{\epsilon_{ij}} = 0$, var($\epsilon_{ij}$) = $\sigma^2$


\subsection*{Estimation of the Model Components}
\begin{itemize}
	\item{Estimation of mean function $\mu$}
	Under the assumption that the mean, covariance and eigenfunctions are smooth, the authors first estimated the mean function $\mu$ based on the pooled data from all individuals.
	The mean function $\mu$ can be estimated by minimizing the following equation \eqref{eq:A2} respect to $\beta_0$ and $\beta_1$, and obtained as $\hat{\mu}(t) = \hat{\beta_0}(t)$.
	Denote kernel functions $\kappa_1: {\rm I\!R} \rightarrow {\rm I\!R} $ and $\kappa_2: {\rm I\!R}^2 \rightarrow {\rm I\!R} $ that satisfy several conditions (omitted here; see appendix of the paper).
	\begin{align}
		\label{eq:A2}
		\sum_{i=1}^{n}\sum_{j=1}^{N_i}\kappa_1(\frac{T_{ij}-t}{h_\mu})\{Y_{ij}-\beta_0-\beta_1(t-T{ij})\}^2{}
	\end{align}

	% 	\[   
	% 	\iint u^{l_1}\nu^{l_2}\kappa_2(u,\nu)dud\nu{} = 
	% 	\left\{
	% \begin{array}{ll}
	%       0 & x\leq l_1+l_2 <l, l_1 \neq \nu_1, l_2 \neq \nu_2 \\
	%       (-1)^{|\nu|}|\nu|! & l_1 = \nu_1, l_2 = \nu_2\\
	%       \neq 0 & l_1 + l_2 = l\\
	% \end{array} 
	% 		\right. \]

	% where $|\nu| = \nu_1 + \nu_2$, kernel functions $\kappa_1: {\rm I\!R} \rightarrow {\rm I\!R} $ and $\kappa_2: {\rm I\!R}^2 \rightarrow {\rm I\!R} $, 

	\item{Estimation of measurement errors $\sigma^2$}
	\begin{align}
	    \label{eq:eq2}
	    \hat{\sigma^2} &= \frac{2}{|\mathcal{T}|}\int_{\mathcal{T}_1}\{\hat{V}(t) - \tilde{G}(t)\}dt 
	\end{align}
	if $\hat{\sigma}^2>0$ and $\hat{\sigma}^2 = 0$ otherwise.
	where $|\mathcal{T}|$ is the length of $\mathcal{T}$, $\mathcal{T_1} = [inf\{x: x \in \mathcal{T}\} + |\mathcal{T}|/4]$.
	In the above equation \eqref{eq:eq2}, $\tilde{G}$ is the diagonal of the surface estimate, $\hat{V}(t)$ is a local linear smoother focusing on diagonal values $\{G(t,t) + \sigma^2\}$ obtained by equation A.1 in the appendix of the paper with $\{G_i(T_{ij}, T_{ij})\}$.


	From \eqref{eq:eq1}, we know $cov(Y_{ij}, Y_{il}) = cov(X(T_{ij}), X(T_{ij}))+\sigma^2\delta_{ij}$, where $\delta_{jl} = 1$ if $j=l$ and $0$ otherwise. 
	Denote ``raw'' covariances: $G_i(T_{ij}, T_{il}) = (Y_{ij}-\hat{\mu}(T_{ij}))(Y_{il}-\hat{\mu}(T_{il}))$.
	It can be shown that $E{\left[G_i(T_{ij}, T_{il})|T_{ij}, T_{il}\right]} \approx cov(X(T_{ij}), X(T_{il})) + \sigma^2 \delta_{jl}$, and thus only $G_i(T_{ij}, T_{il}), j\neq l$ should be included for the covariance surface smoothing step. 
	One-curve-leave-out cross-validation is used to select smoothing parameter. 

	Denote $\hat{G}(s, t)$ be the estimate of $G(s, t)$. 
	The local linear surface smoother for $G(s, t)$ can be estimated by minimizing the following equation \eqref{eq:A3} with respect to $\pmb{\beta} = (\beta_0, \beta_{11}, \beta_{12})$, yielding estimate $\hat{G}(s, t) = \hat{\beta_0}(s,t)$:

	\begin{align}
		\label{eq:A3}
		\sum_{i=1}^{n}\sum_{1 \leq j \neq l \leq N_i}\kappa_2(\frac{T_{ij}-s}{h_G}, \frac{T_{il}-t}{h_G}) \times \{G_i(T_{ij}, T_{il})-f(\pmb{\beta}, (s, t), (T_{ij}, T_{il}))\}^2
	\end{align}

	To obtain the diagonal estimate $\tilde{G}(t)$, the authors rotate x-axis and y-axis by 45-degrees, i.e., $\big(\begin{smallmatrix}
	T_{ij}^* \\
	T_{ik}^*
	\end{smallmatrix}\big) = \big(\begin{smallmatrix}
	\sqrt{2}/2 & \sqrt{2}/2\\
	-\sqrt{2}/2 & \sqrt{2}/2
	\end{smallmatrix}\big)\big(\begin{smallmatrix} 
	T_{ij} \\
	T_{ik}
	\end{smallmatrix}\big)$.  
	Then the authors obtain the surface estimate $\bar{G}(s,t)$ by minimizing the weighted least squares:
	\begin{align}
		\label{eq:A4}
		\sum_{i=1}^{n}\sum_{1 \leq j \neq l \leq N_i}\kappa_2(\frac{T_{ij}^*-s}{h_G}, \frac{T_{il}^*-t}{h_G}) \times \{G_i(T_{ij}^*, T_{il}^*)-f(\pmb{\gamma}, (s, t), (T_{ij}^*, T_{il}^*))\}^2
	\end{align}
	where $g(\pmb{\gamma}, (s, t), (T_{ij}^*, T_{il}^*)) = \gamma_0+\gamma_1(s-T_{ij}^*)+\gamma_2(t-T_{ik}^*)$. Minimizing with respect to $\pmb{\gamma}=(\gamma_1, \gamma_2, \gamma_3)^T$, they get $\bar{G}(s,t) = \hat{\gamma}_0(s,t)$. Finally, $\tilde{G}(t) = \bar{G}(0, t/\sqrt(2))$. 

	\item{Estimation of eigenfunctions and eigenvalues $\phi_k$ and $\lambda_k$}
	\begin{align}
		\label{eq:eq3}
		\int_\mathcal{T} \hat{G}(s,t)\hat{{\phi_k}}(s)ds &= \hat{\lambda_k}\hat{\phi}_k(t)
	\end{align}
	where the $\hat{\phi}_k$ are subject to $\int_\mathcal{T}\hat{\phi}_k(t)^2dt = 1$ and $\int_\mathcal{T}\hat{\phi}_k(t) \times \hat{\phi}_m(t)dt = 0$ for $m<k$.
\end{itemize}


\subsection*{Functional Principal Components Analysis Through Conditional Expectation}
Because of the sparsity of the observations per subject, simply substituting $Y_{ij}$ for $X_i(T_{ij})$ in equation \eqref{eq:eq1} and then estimate $\hat{\xi}_{ik}^S = \sum_{j=1}^{N_i}(Y_{ij}-\hat{\mu}(T_{ij}))\hat{\phi}_k(T_{ij})(T_{ij}-T_{i,j-1})$ setting $T_{i0}=0$ will not provide reasonable approximations to $\hat{\xi}_{ik}^S$. 
Therefore, the authors proposed to estimate FPC scores $\xi_{ik}$ under the assumption that $\xi_{ik}$ and $\epsilon_{ij}$ are jointly Gaussian using:
\begin{align}
	\label{eq:eq5}
	\hat{\xi}_{ik} = \widehat{E}{[\xi_{ik}|\widetilde{\pmb{Y}}_i]} = \hat{\lambda}_k\hat{\pmb{\phi}}_{ik}^T\hat{\pmb{\Sigma}}_{\pmb{Y}_i}^{-1}(\tilde{\pmb{Y}}_i - \hat{\pmb{\mu}}_i)
\end{align}
where the $(j,l)$ th element of $\hat{\mathbf{\Sigma}}_{\mathbf{Y}_i}$ is $(\hat{\mathbf{\Sigma}}_{\mathbf{Y}_i})_{j,l} = \hat{G}(T_{ij}, T_{il}) + \sigma^2\delta_{jl}$. Under the Gaussian assumption, the $\tilde{\xi}_{ik} = E[\xi_{ik}|\widetilde{\pmb{Y}}_i]$ is the best prediction of the FPC score. 
The prediction for the trajectory $X_i(t)$ for the $i$th subject using the first K eigenfunctions is then:
\begin{align}
	\label{eq:eq6}
	\widehat{X_i}^K(t) = \hat{\mu}(t)+\sum_{k=1}^{K}\hat{\hat{\xi}}_{ik}\hat{\phi}_k(t)
\end{align}
From \nameref{simul}, the authors showed that this proposed model is also robust when the Gaussian assumption does not hold. 


\subsection*{Asymptotic Confidence Bands for Individual Trajectories}
The $(1-\alpha)$ asymptotic simultaneous confidence bands for $X_i(t)$ can be obtained:
$
	%\label{eq:eq8}
	\widehat{X}_i^K(t) \pm \sqrt{\chi^2_{K,1-\alpha}\hat{\pmb{\phi}}_{K,t}^T\widehat{\pmb{\Omega}}_K\hat{\pmb{\phi}}_{K,t}}
$, 
where $\chi^2_{K,1-\alpha}$ is the $100(1-\alpha)$th percentile of the chi-squared distribution with K degrees of freedom. 

For all linear combinations of the FPC scores, the authors proved that they could be obtained by:
$
	%\label{eq:eq9}
	\pmb{I}^T\pmb{\xi}_{K,i} \in \pmb{I}^T\hat{\pmb{\xi}}_{K,i} \pm \sqrt{\chi^2_{d,1-\alpha}\pmb{I}^T\widehat{\pmb{\Omega}}\pmb{I}}
$, 
with approximate probability $(1-\alpha)$, where $\mathbf{I}\in \mathcal{A}$, $\mathcal{A} \subseteq {\rm I\!R}^K$ is a linear space with dimension $d\leq K$.


\subsection*{Selection of the Number of Eigenfunctions}
The authors proposed to choose the number of eigenfunctions K that minimizes the cross-validation score:
$%\label{eq:eq10}
	CV(K) = \sum_{i=1}^{n}\sum_{j=1}^{N_i}\{Y_{ij}-\widehat{Y}_i^{(-i)}(T_{ij})\}^2$,
where $\widehat{Y}_i^{(-i)}$ is the predicted curve for the $i$th subject, computed after removing the data for this subject.
$\widehat{Y}_i^{(-i)}(t) = \hat{\mu}^{(-i)}(t) + \sum_{k=1}^{K}\hat{\xi_{ik}}^{(-i)}(t)\hat{\phi}_{k}^{(-i)}(t)$, where $\hat{\xi}_{ik}$ can be obtained from \eqref{eq:eq5}.

The authors also used AIC-type criteria because they found that it was more computationally efficient. 
They generated a pseudo-Gausian log-likelihood 
$
	%\label{eq:eq11}
	\widehat{L} = \sum_{i=1}^n\big\{-\frac{N_i}{2}log(2\pi) - \frac{N_i}{2}log\hat{\sigma}^2 - \frac{1}{2\hat{\sigma}^2}(\widetilde{\pmb{Y}}_i - \hat{\pmb{\mu}}_i - \sum_{k=1}^{K}\hat{\xi}_{ik}\hat{\pmb{\phi}}_{ik})^T \times (\widetilde{\pmb{Y}}_i - \hat{\pmb{\mu}}_i - \sum_{k=1}^{K}\hat{\xi}_{ik}\hat{\pmb{\phi}}_{ik}) \big\}
$, 
where AIC = $-\widehat{L} + K$.

\section{ASYMPTOTIC PROPERTIES}
One major contribution of this paper was that the authors have proved the consistency of the estimated FPC scores $\hat{\xi}_{ik}$ in \eqref{eq:eq5} for the true conditional expectations $\xi_{ik}$. 
Here are several consistency results they proved 
$\underset{t \in \mathcal{T}}{sup}|\hat{\mu}(t) - \mu(t)| = O_p \left(\frac{1}{\sqrt{n}h_{\mu}} \right)$, and $\underset{{t,s} \in \mathcal{T}}{sup}|\hat{G}(s,t) - G(s,t)| = O_p \left(\frac{1}{\sqrt{n}h_{G}^2} \right)$, where $h_{\mu}$, $h_G$ and $h_V$ are bandwidths for estimating $\hat{\mu}$, $\widehat{G}$, $\widehat{V}$ under some conditions. 
From these two asymptotic results, they further obtained the consistency of $\hat{\sigma}^2$: $|\hat{\sigma}^2 - \sigma^2| = O_p\left(\frac{1}{\sqrt{n}} \left(\frac{1}{h_G^2} + \frac{1}{h_V} \right) \right)$.

Under certain conditions (not shown here), the authors also proved that:
$|\hat{\lambda}_k - \lambda_k| = O_p \left(\frac{1}{\sqrt{n}h_{G}^2} \right) $,
$||\hat{\phi}_k - \phi_k||_H = O_p \left(\frac{1}{\sqrt{n}h_{G}^2} \right), k \in \mathcal{T}^{'}$, and $\underset{{t} \in \mathcal{T}}{sup}|\hat{\phi_k}(t) - \phi_k(t)| = O_p \left(\frac{1}{\sqrt{n}h_{G}^2} \right), k \in \mathcal{T}^{'}$. 

Under Gaussian assumption, they also proved that:
$\underset{n \rightarrow \infty}{lim} \hat{\xi}_{ik} = \tilde{\xi}_{ik}$ and for all $t \in \mathcal{T}$, $\underset{K \rightarrow \infty}{lim}\underset{n \rightarrow \infty}{lim} \widehat{X}_i^K(t) = \widetilde{X}_i(t)$ in probability. 

Furthermore, they showed $\underset{K \rightarrow \infty}{lim}\underset{n \rightarrow \infty}{lim} P\left\{\frac{\widehat{X}_i^K(t) - X_i(t)}{\sqrt{\omega_K(t,t)}} \leq x \right\} = \Phi(x) $, where $\Phi(x) $ is the standard Gaussian cdf. 
$\underset{n \rightarrow \infty}{lim} P\left\{ \underset{t \in \mathcal{T}}{sup} \frac{|\widehat{X}_i^K(t) - X_i^K(t)|}{\sqrt{\omega_K(t,t)}} \leq \sqrt{\chi_{K, 1-\alpha}^2} \right \} \geq 1-\alpha $, where $\chi_{K, 1-\alpha}^2$ is the $1-\alpha$th percentile of the chi-squared distribution with K degrees of freedom. 

Because of the space limit of this summary, I cannot go over all the details of the assumptions the authors used to prove the above theories, nor can I list all the consistency properties the authors proved. 
But this is not to undermine the contributions the authors made in the paper. 
In fact, proving the asymptotic properties of the model parameters is one of the major contributions the authors made.  


\section{SIMULATION STUDIES}
\label{simul}
\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
    \includegraphics[width=0.48\textwidth]{Figures/Table1.png}
   	\vspace{-0.5 cm}
\end{wrapfigure}

100 iid normal and 100 iid non-normal samples each consisting of $n = 100$ random trajectories were constructed. 
The simulation conditions are: mean function $\mu(t) = t + sin(t)$, and covariance function derived from two eigenfunctions, $\phi_1(t) = -cos(\pi t/10)/\sqrt{5}$ and $\phi_2(t) = -sin(\pi t/10)/\sqrt{5}, 0 \leq t \leq 10$, where $\lambda_1 = 4, \lambda_2 = 1, \lambda_k = 0, k \geq 3$ as eigenvalue and $\sigma^2 = 0.25$ as the variance of measurement errors $\epsilon_{ij}$ (normal with mean 0) in \eqref{eq:eq1}. 
For the smoothing steps, univariate and bivariate Epanechnikov kernel functions were used: $\kappa_1 (x) = 3/4 (1 - x^2) \mathbbm{1}_{[-1, 1]} (x) $ and $\kappa_2 (x, y) = 9/16 (1 - x^2)(1 - y^2) \mathbbm{1}_{[-1, 1]} (x) \mathbbm{1}_{[-1, 1]} (y)$ where $\mathbbm{1}_A (x) = 1$ if $x \in A$ and 0 otherwise.  
For the 100 normal samples, the FPC scores $\xi_{ik}$ were generated from $N(0,\lambda_k)$, whereas the $\xi_{ik}$ the nonnormal samples were generated from a mixture of two normals, $N(\sqrt{\lambda_k/2}, \lambda_k/2) $ and $ N(-\sqrt{\lambda_k/2}, \lambda_k/2)$ with probability $(1/2, 1/2)$.

The performance was evaluated with mean square error (MSE) and average squared error (ASE score). 
$MSE = \sum_{i = 1}^{n} \int_{0}^{10} \left\{X_i(t) - \widehat{X}_i^K(t) \right\}^2 dt/n $; 
$ASE(\xi_k) = \sum_{i = 1}^n (\hat{\xi}_{ik} - \xi_{ik})^2/n$, k = 1, 2. 

\section{APPLICATIONS}

\noindent \textbf{Objectives:} Using PACE, the authors tried to show that they were able 1) to estimate the overall trend over time, 2) to study subject-specific variation patterns, 3) to uncover the dominant modes of variation, and 4) to recover individual trajectories from sparse measurements.

\subsection*{Longitudinal CD4 Counts}
\noindent \underline{Dateset:} A cohort of 283 homosexual men who became HIV-positive between 1984 and 1991 \cite{Kaslow1987}. 
CD4 counts and CD4 percentage, which are markers for the health status of HIV infected individuals, and other clinical tests were recorded.
All individuals were scheduled to have clinical measurements at their semiannual visits. 
However, many individuals missed their visits and the HIV infections occurred at different time points randomly. 
Therefore, the data are sparse and the repeated measurements were irregular. 

\begin{wrapfigure}{r}{0.65\textwidth}
  \vspace{-1 cm}
  \centering
    \includegraphics[width=0.64\textwidth]{Figures/Figure1.png}
   	\vspace{-0.7 cm}
   	\caption{(a) Individual trajectories of CD4 percentage in 283 individuals. (b) Smooth estimate of the mean function. (c) Smooth estimate of the variance function for CD4 counts. (d) Smooth estimate of correlation function. }
   	\vspace{-0.3 cm}
	\label{fig:fig1}
\end{wrapfigure}

\noindent \underline{Observations:} 1) The estimate of mean function was able to be build from individual's trajectory. 
From Figure ~\ref{fig:fig1} (b), we can see that the CD4 cell counts are decreasing over a five year course. 

\noindent 2) Variance is non-stationary (decreases at early times and then increase again; see Figure ~\ref{fig:fig1} (c)). 
Correlations between same subjects are strong, but the correlations between early and late CD counts dies off (see Figure ~\ref{fig:fig1} (d)). 

\noindent 3) $K = 3$ was chosen from both one-curve-leave-out cross-validation and AIC, and the resulting three eigenfunctions account for 76.9\%, 12.3\%, and 8.1\% of the total variation. 
Most of the variability is thus in the direction of overall CD4 percentage level.  

\begin{wrapfigure}{l}{0.6\textwidth}
  \centering
    \includegraphics[width=0.59\textwidth]{Figures/Figure5.png}
   	\vspace{-0.5 cm}
   	\caption{Observations (circles), predicted (solid lines) trajectories, and 95\% pointwise (dashed lines) and simultaneous (dotted lines) bands for four randomly chosen individuals, for the CD4 count data.}
	\label{fig:fig5}
	\vspace{-0.7 cm}
\end{wrapfigure}

\noindent 4) The predicted curves and 95\% pointwise and simultaneous confidence bands were shown in Figure ~\ref{fig:fig5}.
It shows that even when the observations per subject is sparse, PACE was still able to effectively recover the trajectories. 
An extreme case was exemplified by the left bottom subfigure, where only one observation was used. 
They showed that they were able to generate reasonably decent trajectory.

\subsection*{Yeast Cell Cycle Gene Expression Profiles}
\noindent \underline{Dateset:} Another dataset the authors used to benchmark their method was the yeast cell cycle data from Spellman et al \cite{Spellman1998}. 
The training set include 6178 genes with each gene expression profile consists of 18 data points, measured every 7 minutes in a span of 0 to 119 minutes. 
The authors artificially induced sparsity to the data by randomly selecting $N_i \; \in (1 - 6)$ with equal probability, and then randomly select from the 18 recorded gene expression measurements (the median of the number of observations per gene expression profile is 3).  %; see Figure ~\ref{fig:fig6}). 

% \begin{wrapfigure}{l}{0.6\textwidth} 
% 	\centering
% 	    \includegraphics[width=0.59\textwidth]{Figures/Figure7.png}
% 	   	\vspace{-0.5 cm}
% 	   	\caption{Smooth surface estimates $\widehat{G}$ of the covariance functions from the complete data (a) and from the sparsified data (b).}
% 		\label{fig:fig7}
% \end{wrapfigure}

\noindent \underline{Observations:} 1) The mean function estimates for sparse and complete data are close to each other and show periodic features (not shown here).

\noindent 2) The covariance function obtained from complete and ``sparsified'' data set are similar to each other and exhibit periodic features. % (Figure ~\ref{fig:fig7}). 

\noindent 3) The first eigenfunctions were able to approximate the expression profiles (Figure ~\ref{fig:fig8}), which explain approximately 75\% of the total variation.

\noindent 4) 95\% confidence bands were generated using PACE. 
The predictions obtained from the sparse data are similar to those constructed from the complete data (Figure ~\ref{fig:fig8}).

All of these observations demonstrate that the PACE method effectively recover entire individual trajectories from a proportion of the data. 

\begin{wrapfigure}{r}{0.65\textwidth} 
	\centering
		\vspace{-1 cm}
	    \includegraphics[width=0.64\textwidth]{Figures/Figure8.png}
	   	\vspace{-0.5 cm}
	   	\caption{Smooth estimates of the mean function (a), the first (b) and second (c) eigenfunctions, obtained from sparse (solid lines) and complete (dashed lines) data.}
	   	\vspace{-0.5 cm}
		\label{fig:fig8}
\end{wrapfigure}

\section{CONCLUSIONS}
The authors extended the traditional FPC analysis and developed a method which depends on conditional expectations, which they call ``PACE''.
They showed that PACE was able to handle longitudinal data with irregular measurements and sparse data. 
Using a simulation study and two real-life datasets, they showed that not only PACE effectively recovered the estimation of overall trend of random trajectories, but also allow them to study the subject-specific variation patterns. 
Furthermore, using real datasets, they showed that PACE was able to help impute missing data in longitudinal studies. 
By replacing the integrals by conditional exceptions when estimating FPC scores, PACE improves the traditional FPC analysis under both dense and regular designs. 
This conditional expectation step can be interpreted as shrinkage of the random effects toward 0.  
Overall, PACE shows promise in applications of both longitudinal designs. 


\section{FUTURE RESEARCH}
To make the model more flexible, the authors could investigate extending ``PACE''to additive models. 
The challenge of additive model in functional study could be that the predictor set is not countable and the additive models may require many additive components. 
But because this paper was published a while ago, the authors have done some research on fitting functional additive models \cite{Muller2008}. 
Another area the authors can investigate is how to classify the functional data. 
In practice, it's very often that we need to compare two or more groups of longitudinal data. 
% Another possible research area could be investigating how to estimate the functional gradients of the response with respect to the predictor functions, which would provide quantitative measures of 
% G: $\pmb{z}\sim p_{\pmb{z}} \longmapsto $ Image Space (to generate realistic images)

% \vspace{3mm}
% D: $h\sim p_{data} \longmapsto $ Likelihood (to play an adversarial role)

% \newpage
% \section*{References}

\bibliographystyle{unsrt}
\bibliography{ref} 



\end{document}
